{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"..\\data\\processed\\credit_card_cleaned.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns based on business domain and understanding from EDA\n",
    "# required_cols = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'DEFAULT', 'age_group']\n",
    "# df = df[required_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a96aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 18-25: Young adults, limited credit history\n",
    "# - 26-35: Early career, establishing credit\n",
    "# - 36-50: Established career, stable income\n",
    "# - 51-65: Peak earning years\n",
    "# - 65+: Retirement age, fixed income\n",
    "\n",
    "df[\"age_group_dk\"] = pd.cut(\n",
    "    df[\"AGE\"],\n",
    "    bins=[18, 25, 35, 50, 65, 100],\n",
    "    labels=[\"18-25\", \"26-35\", \"36-50\", \"51-65\", \"65+\"],\n",
    ")\n",
    "\n",
    "mapping = dict(\n",
    "    zip(\n",
    "        [\"18-25\", \"26-35\", \"36-50\", \"51-65\", \"65+\"],\n",
    "        [\n",
    "            \"Young adults\",\n",
    "            \"Early aareer\",\n",
    "            \"Established career\",\n",
    "            \"Peak earning years\",\n",
    "            \"Retirment age\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "df['age_category'] = df[\"age_group_dk\"].map(mapping)\n",
    "df = df.drop(columns=['AGE', 'age_group', 'age_group_dk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.drop('DEFAULT', axis=1).select_dtypes(include='number').columns\n",
    "\n",
    "df_encoded = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"SEX\", \"EDUCATION\", \"MARRIAGE\", \"age_category\"],\n",
    "    drop_first=True,\n",
    "    \n",
    ")\n",
    "\n",
    "X = df_encoded.drop('DEFAULT', axis=1)\n",
    "y = df_encoded['DEFAULT']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y   # to ensure that the class distribution remains consistent across both the training and test sets\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training set default rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test set default rate: {y_test.mean():.2%}\")\n",
    "\n",
    "smote = SMOTE(random_state=123, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nAfter SMOTE:\")\n",
    "print(f\"Training samples: {len(X_train_smote)}\")\n",
    "print(pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "categorical_cols = df_encoded.select_dtypes(include='bool').columns\n",
    "categorical_cols\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_numerical= scaler.fit_transform(X_train_smote[numerical_cols])\n",
    "X_test_scaled_numerical= scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "X_train_scaled_numerical = pd.DataFrame(X_train_scaled_numerical, columns=X_train_smote[numerical_cols].columns, index=X_train_smote.index)\n",
    "X_test_scaled_numerical = pd.DataFrame(X_train_scaled_numerical, columns=X_test[numerical_cols].columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8032c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_categorical = X_train_smote[categorical_cols]\n",
    "X_test_categorical = X_test[categorical_cols]\n",
    "\n",
    "X_train_final = pd.concat([X_train_scaled_numerical, X_train_categorical], axis=1)\n",
    "X_test_final = pd.concat([X_test_scaled_numerical, X_test_categorical], axis=1)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_final)\n",
    "X_test_pca = pca.transform(X_test_final)\n",
    "\n",
    "\n",
    "# Train SVC\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "model.fit(X_train_pca, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(X_train_final, y_train_smote)\n",
    "\n",
    "y_pred = svm.predict(X_test_final)\n",
    "# y_pred_prob = svm.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "#train a logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_model.fit(X_train_final, y_train_smote)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test_final)\n",
    "y_pred_prob = logistic_model.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train_final, y_train_smote)\n",
    "y_pred = rf.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred_prob = rf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, rf.predict(X_test_final)), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Logistic Regression', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
